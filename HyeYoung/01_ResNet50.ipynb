{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN4N3auLfOE6RWELeQVisTu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5kfUG4FSiPuK","executionInfo":{"status":"ok","timestamp":1732549522894,"user_tz":-540,"elapsed":19710,"user":{"displayName":"data5 Play","userId":"13112719228764830319"}},"outputId":"8c9d115f-1eaf-4c1c-b978-7b52171b4039"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (original): http://drive.google.com/uc?id=1iS1F7R1waTTOmL7Ab9i2ULQTqj8tIhee\n","From (redirected): https://drive.google.com/uc?id=1iS1F7R1waTTOmL7Ab9i2ULQTqj8tIhee&confirm=t&uuid=8b5f7cc2-fd0a-4d36-bf06-df11d2918ca6\n","To: /content/data.zip\n","100%|██████████| 557M/557M [00:11<00:00, 48.8MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["압축 해제 완료: furniture\n","압축 해제된 파일 및 폴더 목록:\n","['data']\n"]}],"source":["# @title 데이터취득\n","# https://drive.google.com/file/d/1iS1F7R1waTTOmL7Ab9i2ULQTqj8tIhee/view?usp=sharing\n","\n","import gdown, os, zipfile\n","\n","file_id = '1iS1F7R1waTTOmL7Ab9i2ULQTqj8tIhee'\n","output = 'data.zip'\n","\n","gdown.download(f'http://drive.google.com/uc?id={file_id}', output, quiet=False)\n","\n","output_dir = 'furniture'\n","os.makedirs(output_dir, exist_ok=True)  # 폴더가 없으면 생성\n","\n","with zipfile.ZipFile(output, 'r') as z:\n","    z.extractall(output_dir)  # output_dir에 압축 해제\n","    print(f\"압축 해제 완료: {output_dir}\")\n","\n","# 압축 해제된 폴더 내용 확인\n","print(\"압축 해제된 파일 및 폴더 목록:\")\n","print(os.listdir(output_dir))\n"]},{"cell_type":"code","source":["# @title Sequence 객체 만들기\n","from tensorflow.keras.utils import Sequence\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","from sklearn.utils import shuffle\n","\n","class FurnitureSequence(Sequence):\n","  def __init__(self, images, labels, batch_size=32, image_size=224, augmentor=None, preprocess_function=None, shuffle=True):\n","    self.images = images\n","    self.labels = labels\n","    self.batch_size = batch_size\n","    self.image_size = image_size\n","    self.augmentor = augmentor\n","    self.preprocess_function = preprocess_function\n","    self.shuffle = shuffle\n","    self.indexes = np.arange(len(images))\n","    if self.shuffle:\n","      np.random.shuffle(self.indexes)\n","\n","  def __len__(self):\n","    return int(np.ceil(len(self.images) / self.batch_size)) # 배치 사이즈만큼 돌리기\n","\n","  def __getitem__(self, index): #index번재 배치 데이터 반환\n","    start = index * self.batch_size\n","    end = (index + 1) * self.batch_size\n","    this_batch_images = self.images[start:end]\n","    batch_labels = self.labels[start:end] if self.labels is not None else None # 예측에는 라벨 필요없음\n","\n","    # 배치 크기에 맞는 배열 초기화 (리사이즈된 결과를 저장할 새로운 배열 필요)\n","    batch_images = np.zeros((this_batch_images.shape[0], self.image_size, self.image_size, 3), dtype=np.float32)\n","\n","    for i in range(this_batch_images.shape[0]):\n","      image = this_batch_images[i]\n","\n","      # 데이터 증강 적용\n","      if self.augmentor is not None:\n","        image = self.augmentor(image)['image'] # augment 딕셔너리 반환해서, 필요한 데이터(이미지만 추출)만 명시적으로 추출, 데이터 증강 도구는 이미지 외의 데이터를 함께 처리할 수 있어서('mask','bboxes' 등)\n","\n","      # 리사이즈\n","      image = cv2.resize(image,(self.image_size, self.image_size))\n","\n","      # 전처리\n","      if self.preprocess_function is not None:\n","        image = self.preprocess_function(image)\n","\n","      batch_images[i] = image\n","\n","    return (batch_images, batch_labels) if self.labels is not None else batch_images\n","\n","    def on_epoch_end(self): # 에포크 종료 후 데이터 섞기.\n","        if self.shuffle:\n","            self.images, self.labels = shuffle(self.images, self.labels)\n","\n","\n","\n"],"metadata":{"id":"TUE-s7YopDjZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 데이터 준비\n","\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","\n","# 이미지와 레이블 준비 (예: NumPy 배열)\n","images = np.random.rand(1000, 256, 256, 3)  # 가상 이미지 데이터\n","labels = np.random.randint(0, 4, size=(1000,))  # 4개의 클래스\n","\n","# One-Hot Encoding\n","from tensorflow.keras.utils import to_categorical\n","labels = to_categorical(labels, num_classes=4)\n"],"metadata":{"id":"AflDy1dVwK0X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","\n","# 데이터 분할\n","train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.3, random_state=42)\n","tr_images, val_images, tr_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n","\n","# Sequence 객체 생성\n","train_seq = FurnitureSequence(tr_images, tr_labels, batch_size=32, image_size=224, preprocess_function=preprocess_input, shuffle=True)\n","val_seq = FurnitureSequence(val_images, val_labels, batch_size=32, image_size=224, preprocess_function=preprocess_input, shuffle=False)\n","test_seq = FurnitureSequence(test_images, test_labels, batch_size=32, image_size=224, preprocess_function=preprocess_input, shuffle=False)\n","\n","tr_batch_images, tr_batch_labels = next(iter(train_seq)) # seq객체 next로 보고싶으면 iter객체로 감싸서 볼 수 있고, 배치 이미지를 반환함\n","tr_batch_images.shape, tr_batch_labels.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mUJ4Y1Ik252K","executionInfo":{"status":"ok","timestamp":1732549527077,"user_tz":-540,"elapsed":1046,"user":{"displayName":"data5 Play","userId":"13112719228764830319"}},"outputId":"ef40555d-9732-482d-b329-50bc67513282"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((32, 224, 224, 3), (32, 4))"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"],"metadata":{"id":"28uNEf294KaW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 모델 생성\n","\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","\n","# ResNet50 기본 모델 로드 (ImageNet 가중치 사용)\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# 새로운 Fully Connected Layer 추가\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)  # Global Average Pooling\n","x = Dense(1024, activation='relu')(x)  # Fully Connected Layer\n","predictions = Dense(4, activation='softmax')(x)  # 최종 출력층 (4개의 클래스)\n","\n","# 최종 모델 정의\n","model = Model(inputs=base_model.input, outputs=predictions)"],"metadata":{"id":"QVLVnZfw3xw9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ResNet50의 기존 층 동결\n","for layer in base_model.layers:\n","    layer.trainable = False"],"metadata":{"id":"xj0J9Zfr33bO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 모델 컴파일\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","model.compile(optimizer=Adam(learning_rate=0.001),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# 콜백설정\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n","\n","reduce_lr_on_plateau_cb =  ReduceLROnPlateau(patience=3, factor=0.5, verbose=1)\n","early_stop = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', restore_best_weights=True)\n","callbacks = [reduce_lr_on_plateau_cb, early_stop]\n"],"metadata":{"id":"HPEZr8vF86Dd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @ tutle 모델 학습\n","history = model.fit(\n","    train_seq,\n","    validation_data=val_seq,\n","    epochs=30,\n","    callbacks=callbacks\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SrFWxF6S9ApO","executionInfo":{"status":"ok","timestamp":1732549573263,"user_tz":-540,"elapsed":44624,"user":{"displayName":"data5 Play","userId":"13112719228764830319"}},"outputId":"d9b42e31-cc2c-47b9-c7d6-d82bd1b1b9d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 532ms/step - accuracy: 0.2374 - loss: 1.7965 - val_accuracy: 0.2786 - val_loss: 1.4564 - learning_rate: 0.0010\n","Epoch 2/30\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.2411 - loss: 1.5405 - val_accuracy: 0.2000 - val_loss: 1.5497 - learning_rate: 0.0010\n","Epoch 3/30\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.2360 - loss: 1.5334 - val_accuracy: 0.2000 - val_loss: 1.5021 - learning_rate: 0.0010\n","Epoch 4/30\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.2433 - loss: 1.4836\n","Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.2432 - loss: 1.4837 - val_accuracy: 0.2214 - val_loss: 1.4636 - learning_rate: 0.0010\n","Epoch 5/30\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - accuracy: 0.2647 - loss: 1.4641 - val_accuracy: 0.2214 - val_loss: 1.4185 - learning_rate: 5.0000e-04\n","Epoch 6/30\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.2296 - loss: 1.4142 - val_accuracy: 0.2000 - val_loss: 1.4746 - learning_rate: 5.0000e-04\n"]}]},{"cell_type":"code","source":["# @ title 동결 해제 후 미세 조정(fine-Tuning)\n","\n","# ResNet50의 상위 20개 층 동결 해제\n","for layer in base_model.layers[-20:]:\n","    layer.trainable = True\n","\n","# 모델 재컴파일 (학습률을 낮춤)\n","model.compile(optimizer=Adam(learning_rate=1e-5),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Fine-Tuning 학습\n","history_fine = model.fit(\n","    train_seq,\n","    validation_data=val_seq,\n","    epochs=30,\n","    callbacks=callbacks\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lbppUJJU9qz2","executionInfo":{"status":"ok","timestamp":1732549616174,"user_tz":-540,"elapsed":42956,"user":{"displayName":"data5 Play","userId":"13112719228764830319"}},"outputId":"372990a6-2d37-4594-e207-39ca1d2efdec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 777ms/step - accuracy: 0.2518 - loss: 1.4122 - val_accuracy: 0.2786 - val_loss: 1.4409 - learning_rate: 1.0000e-05\n","Epoch 2/30\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 127ms/step - accuracy: 0.2955 - loss: 1.3839 - val_accuracy: 0.2786 - val_loss: 1.4355 - learning_rate: 1.0000e-05\n","Epoch 3/30\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.3084 - loss: 1.3677 - val_accuracy: 0.2786 - val_loss: 1.4298 - learning_rate: 1.0000e-05\n","Epoch 4/30\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - accuracy: 0.3360 - loss: 1.3625 - val_accuracy: 0.2786 - val_loss: 1.4154 - learning_rate: 1.0000e-05\n","Epoch 5/30\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.4083 - loss: 1.3494 - val_accuracy: 0.2786 - val_loss: 1.4046 - learning_rate: 1.0000e-05\n"]}]},{"cell_type":"code","source":["# @title 모델 평가\n","loss, accuracy = model.evaluate(test_seq)\n","print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JyNXUsVu-bCF","executionInfo":{"status":"ok","timestamp":1732549837314,"user_tz":-540,"elapsed":1619,"user":{"displayName":"data5 Play","userId":"13112719228764830319"}},"outputId":"8b82b273-358a-434d-ee7b-7ef3f6da3c3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.2969 - loss: 1.4187\n","Test Accuracy: 26.33%\n"]}]},{"cell_type":"code","source":["# @title 테스트 이미지 예측\n","\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","# 테스트 이미지 로드\n","img_path = '/content/의자.jpeg'  # 테스트 이미지 경로\n","img = image.load_img(img_path, target_size=(224, 224))  # ResNet 입력 크기에 맞게 리사이즈\n","img_array = image.img_to_array(img) / 255.0  # 정규화\n","img_array = np.expand_dims(img_array, axis=0)  # 배치 차원 추가\n","\n","# 예측 수행\n","predictions = model.predict(img_array)\n","predicted_class = np.argmax(predictions)\n","class_labels = ['밥상', '의자', '소파', '서랍장']\n","\n","print(f\"Predicted Class: {class_labels[predicted_class]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qj1Hm61N-xLK","executionInfo":{"status":"ok","timestamp":1732549839674,"user_tz":-540,"elapsed":425,"user":{"displayName":"data5 Play","userId":"13112719228764830319"}},"outputId":"9826c963-f779-4a57-ce99-9db84214a9bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Predicted Class: 서랍장\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ejMXZg5Y_OVb"},"execution_count":null,"outputs":[]}]}