{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0YTjmW5_b7q"
   },
   "source": [
    "# 가구40 InceptionV3 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9tm8FNnCiqh"
   },
   "source": [
    "## 데이터 취득"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VxfDANiCkYo",
    "outputId": "8eb99c4e-9234-4ae0-cce5-b1b8a05fcdb4",
    "ExecuteTime": {
     "end_time": "2024-11-27T07:24:18.321255Z",
     "start_time": "2024-11-27T07:24:08.294804Z"
    }
   },
   "source": [
    "# https://drive.google.com/file/d/18Qj8lEd4DxMSgxYeNMlT3vKYfYs_k8Zj/view?usp=sharing\n",
    "import gdown, zipfile, os\n",
    "\n",
    "file_id = '18Qj8lEd4DxMSgxYeNMlT3vKYfYs_k8Zj'\n",
    "output = 'file.zip'\n",
    "\n",
    "gdown.download(f'https://drive.google.com/uc?id={file_id}', output, quiet=False)\n",
    "\n",
    "output_dir = 'furniture40'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(output, 'r') as z:\n",
    "    z.extractall(output_dir)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=18Qj8lEd4DxMSgxYeNMlT3vKYfYs_k8Zj\n",
      "To: C:\\DA36\\workspaces\\mini3\\ShimJeongseok\\file.zip\n",
      "100%|██████████| 25.7M/25.7M [00:01<00:00, 21.7MB/s]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KMvo0uby_Hq7",
    "ExecuteTime": {
     "end_time": "2024-11-27T07:24:00.960865Z",
     "start_time": "2024-11-27T07:23:54.877811Z"
    }
   },
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ERs3Njm0IcTO",
    "ExecuteTime": {
     "end_time": "2024-11-27T07:28:15.444968Z",
     "start_time": "2024-11-27T07:28:14.045202Z"
    }
   },
   "source": [
    "import cv2\n",
    "# 데이터 디렉토리 설정\n",
    "data_dir = 'C:\\\\DA36\\\\workspaces\\\\mini3\\\\ShimJeongseok\\\\furniture40\\\\resized_data_40'\n",
    "IMAGE_SIZE = (299, 299)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "class_names = os.listdir(data_dir)\n",
    "\n",
    "class_mapping = {}\n",
    "for idx, name in enumerate(class_names):\n",
    "    class_mapping[name] = idx\n",
    "# {0 : cabinet, 1 : chair....)\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for class_name, class_idx in class_mapping.items():\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    for file_name in os.listdir(class_dir):\n",
    "        file_path = os.path.join(class_dir, file_name)\n",
    "        image = cv2.imread(file_path)\n",
    "        if image is not None:  # 이미지가 정상적으로 로드되었는지 확인\n",
    "            images.append(image)\n",
    "            labels.append(class_idx)\n",
    "\n",
    "# Numpy 배열로 변환\n",
    "images = np.array(images, dtype=np.float32) / 255.0  # 정규화\n",
    "labels = np.array(labels, dtype=np.int32)  # 라벨은 정수 배열로"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "yBxRs5ifDWpS",
    "ExecuteTime": {
     "end_time": "2024-11-27T07:28:23.682976Z",
     "start_time": "2024-11-27T07:28:18.923660Z"
    }
   },
   "source": [
    "# 전이학습\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "base_model = Xception(input_shape=(299, 299, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "for layer in base_model.layers[-40:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# 새로운 출력층 추가\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = Dense(2048, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# model.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001B[1m83683744/83683744\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 0us/step\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZJ09MnSL_oKw",
    "ExecuteTime": {
     "end_time": "2024-11-27T07:28:28.683907Z",
     "start_time": "2024-11-27T07:28:27.486899Z"
    }
   },
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 299\n",
    "\n",
    "class Furniture40Sequence(Sequence):\n",
    "    def __init__(self, images, labels, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, augmentor=None, shuffle=False, preprocess_function=None):\n",
    "        self.images = images # path가 아닌 이미지 픽셀 데이터(ndarray)\n",
    "        self.labels = labels # fit/evaluate에는 label데이터가 있지만, predict에는 label데이터가 없다.\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.augmentor = augmentor\n",
    "        self.shuffle = shuffle\n",
    "        self.preprocess_function = preprocess_function # 스케일링 함수\n",
    "        self.on_epoch_end() # shuffle 처리\n",
    "\n",
    "    def __len__(self):\n",
    "        # 이 데이터셋은 몇개의 batch로 구성되었는가\n",
    "        return int(np.ceil(len(self.images) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 이번 배치용 이미지/라벨 선정\n",
    "        start = index * self.batch_size\n",
    "        end = (index + 1) * self.batch_size\n",
    "        this_batch_images = self.images[start:end]\n",
    "        batch_labels = self.labels[start:end] if self.labels is not None else None\n",
    "        batch_images = np.zeros((this_batch_images.shape[0], self.image_size, self.image_size, 3), dtype=np.float32)\n",
    "\n",
    "        for i in range(this_batch_images.shape[0]): # 이번 배치 이미지만큼 반복\n",
    "            image = this_batch_images[i]\n",
    "\n",
    "            # 데이터 증강\n",
    "            if self.augmentor is not None:\n",
    "                image = self.augmentor(image)['image']\n",
    "\n",
    "            # 리사이즈\n",
    "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # 스케일링\n",
    "            if self.preprocess_function is not None:\n",
    "                image = self.preprocess_function(image)\n",
    "\n",
    "            batch_images[i] = image\n",
    "\n",
    "        return (batch_images, batch_labels) if self.labels is not None else batch_images\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.images, self.labels = shuffle(self.images, self.labels)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q26NnRzj_vcQ",
    "outputId": "2d14994f-2b74-4e59-925d-09fff8ea7df7",
    "ExecuteTime": {
     "end_time": "2024-11-27T07:28:33.208472Z",
     "start_time": "2024-11-27T07:28:32.871392Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=0, stratify=labels)\n",
    "\n",
    "# one-hot encoding\n",
    "y_train_one_hot = to_categorical(y_train, 4)\n",
    "y_test_one_hot = to_categorical(y_test, 4)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((643, 224, 224, 3), (161, 224, 224, 3), (643,), (161,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pBjuQwKOQRxN",
    "outputId": "2efd85a2-0d8d-4046-97fd-b3d3d0244a08",
    "ExecuteTime": {
     "end_time": "2024-11-27T07:28:43.505359Z",
     "start_time": "2024-11-27T07:28:43.262716Z"
    }
   },
   "source": [
    "# 학습/검증/평가용 Sequence객체 준비\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "\n",
    "tr_seq = Furniture40Sequence(X_train, y_train_one_hot, preprocess_function=preprocess_input, shuffle=True)\n",
    "val_seq = Furniture40Sequence(X_test, y_test_one_hot, preprocess_function=preprocess_input, shuffle=False)\n",
    "test_seq = Furniture40Sequence(X_test, y_test_one_hot, preprocess_function=preprocess_input, shuffle=False)\n",
    "\n",
    "tr_batch_images, tr_batch_labels = next(iter(tr_seq))\n",
    "tr_batch_images.shape, tr_batch_labels.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 299, 299, 3), (64, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 834
    },
    "id": "D7Rk3UuKQWjd",
    "outputId": "8d8da38d-454e-4fcf-d55b-1ea698db6600",
    "ExecuteTime": {
     "end_time": "2024-11-27T07:50:09.379473100Z",
     "start_time": "2024-11-27T07:28:52.897413Z"
    }
   },
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "# class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = EarlyStopping(patience=6, verbose=1, restore_best_weights=True)\n",
    "reduce_lr_on_plateau_cb = ReduceLROnPlateau(patience=3, factor=0.5, verbose=1)\n",
    "\n",
    "# 학습\n",
    "history = model.fit(tr_seq, validation_data=val_seq, epochs=50, callbacks=[early_stopping_cb, reduce_lr_on_plateau_cb])\n",
    "\n",
    "# 학습결과 시각화\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.show()\n",
    "\n",
    "# 평가\n",
    "loss, accuracy = model.evaluate(test_seq)\n",
    "print(f'loss: {loss:.4f}, accuracy: {accuracy:.4f}')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\playdata2\\miniconda3\\envs\\mini3_env\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m 4/11\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m35:26\u001B[0m 304s/step - accuracy: 0.3298 - loss: 1.3715"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m reduce_lr_on_plateau_cb \u001B[38;5;241m=\u001B[39m ReduceLROnPlateau(patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, factor\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# 학습\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr_seq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_seq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping_cb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce_lr_on_plateau_cb\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# 학습결과 시각화\u001B[39;00m\n\u001B[0;32m     16\u001B[0m pd\u001B[38;5;241m.\u001B[39mDataFrame(history\u001B[38;5;241m.\u001B[39mhistory)\u001B[38;5;241m.\u001B[39mplot()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mini3_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mini3_env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:368\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator:\n\u001B[0;32m    367\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m--> 368\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    369\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(step, logs)\n\u001B[0;32m    370\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mini3_env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:216\u001B[0m, in \u001B[0;36mTensorFlowTrainer._make_function.<locals>.function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfunction\u001B[39m(iterator):\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[0;32m    214\u001B[0m         iterator, (tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mIterator, tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mDistributedIterator)\n\u001B[0;32m    215\u001B[0m     ):\n\u001B[1;32m--> 216\u001B[0m         opt_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmulti_step_on_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    217\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m opt_outputs\u001B[38;5;241m.\u001B[39mhas_value():\n\u001B[0;32m    218\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mini3_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mini3_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mini3_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    875\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    876\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 878\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[0;32m    880\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[0;32m    882\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    883\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mini3_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mini3_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1324\u001B[0m     args,\n\u001B[0;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1326\u001B[0m     executing_eagerly)\n\u001B[0;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mini3_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mini3_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    261\u001B[0m     )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mini3_env\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1550\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1552\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1553\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1554\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1555\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1556\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1557\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1558\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1560\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1561\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1562\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1566\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1567\u001B[0m   )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mini3_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
